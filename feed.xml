<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://raymond112514.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://raymond112514.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-25T00:12:54+00:00</updated><id>https://raymond112514.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Introduction to Statistical Learning Theory</title><link href="https://raymond112514.github.io/blog/2025/blog-one/" rel="alternate" type="text/html" title="Introduction to Statistical Learning Theory"/><published>2025-03-24T00:00:00+00:00</published><updated>2025-03-24T00:00:00+00:00</updated><id>https://raymond112514.github.io/blog/2025/blog-one</id><content type="html" xml:base="https://raymond112514.github.io/blog/2025/blog-one/"><![CDATA[<style>.post{line-height:2.0}</style> <h3 id="empirical-risk-minimization">Empirical Risk Minimization</h3> <p>In a standard supervised learning setup, we are given two space $\mathcal{X}, \mathcal{Y}$ and the goal is to learn a function $f\in \mathcal{F}$ that predicts $y\in \mathcal{Y}$ given $x\in \mathcal{X}$. This can be done through solving the optimization problem:</p> \[f^*=\text{argmin}_{f\in \mathcal{F}} \underbrace{\mathbb{E}_{X, Y\sim \mathcal{X}, \mathcal{Y}} [\ell(f(X), Y)]}_{R(f)}\] <p>Where $\ell:\mathcal{Y}\times \mathcal{Y}\rightarrow \mathbb{R}$ is called the loss function and measures the error between the estimate $f(X)$ and the ground truth $Y$ and the $R(f)$ is called the risk of $f$. Putting the optimization problem in words, we want to find a function such that the average error is low. Solving this problem is practice poses two challenges:</p> <ol> <li>It’s hard to optimize over the space of functions $\mathcal{F}$, and</li> <li>Even evaluating the objective $R(f)$ requires performing integration over high dimensional space, which is hard.</li> </ol> <p>The first problem is easy to solve: we just consider a parameterized family of function ${f_\theta:\theta\in \Theta}$. Now we can use algorithms like gradient descent to find the optimal parameter. To solve the second problem, instead of optimizing over the expectation, we estimate the expectation using sample averages. In other words, we instead solve the following optimization problem</p> \[\hat{f}=\text{argmin}_{f\in \mathcal{F}} \underbrace{\frac{1}{n}\sum_{i=1}^n \ell(f(X_i), Y_i)}_{\hat{R}_n(f)}\] <p>Where ${(X_i, Y_i)}<em>{i\in [n]}$, sometimes called the training set, are i.i.d. samples from $\mathcal{X}\times \mathcal{Y}$. We call the $\hat{R}_n(f)$ term the empiricial risk on $f$. Since $\hat{f}$ is the minimizer on the dataset $\mathcal{D}={(X_i, Y_i)}</em>{i\in [n]}$, we know that the average risk of $\hat{f}$, but what we actually want is low risk on the set $\mathcal{X}\times\mathcal{Y}$.</p>]]></content><author><name></name></author><category term="blog"/><category term="optimization"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Introduction to Nonlinear Optimization</title><link href="https://raymond112514.github.io/blog/2025/descent-methods/" rel="alternate" type="text/html" title="Introduction to Nonlinear Optimization"/><published>2025-03-24T00:00:00+00:00</published><updated>2025-03-24T00:00:00+00:00</updated><id>https://raymond112514.github.io/blog/2025/descent-methods</id><content type="html" xml:base="https://raymond112514.github.io/blog/2025/descent-methods/"><![CDATA[<style>.post{line-height:2.0}</style> <h3 id="problem-setup">Problem Setup</h3> <p>The problem setup for optimization problem is quite simple: given a function $f:\mathbb{R}^n\rightarrow \mathbb{R}$ and some constrained set $C$, we want to solve:</p> \[\min_{x\in C}f(x)\] <p>For the first few blogs, we will consider the simple case where $C=\mathbb{R}^n$. In this case, the problem is an unconstrained optimization problem. Generally speaking, we require $f$ to have continuous derivative up to second order. In some algorithms, though, only continuity up to first order is needed. We also assume that $f$ is in general nonconvex.</p> <h3 id="preliminaries">Preliminaries</h3> <p>We first state some basic results that will be used later. One of the most important ones is Taylor’s theorem, on a high level, it tells us that we can approximate $f$ with some degree $n$ polynomial with high order error term. <br/></p> <p><strong>Theorem (Taylor)</strong>: Suppose $f:\mathbb{R}^n\rightarrow \mathbb{R}$ has continuous derivate up to order $2$, then for all $x,p\in \mathbb{R}^n$, there exists $t\in (0,1)$ such that</p> \[f(x+p)=f(x)+\nabla f(x+tp)^T p\] \[f(x+p)=f(x)+\nabla f(x)^Tp + \frac{1}{2}p^T\nabla^2 f(x+tp)p\] <h3 id="descent-method-recipe">Descent Method: Recipe</h3> <p>One common algorithm used to solve optimization problem is descent method. On a high level,descent method works iteratively, starting with some randomly chosen point $x_0$, and then updates the estimate gradually, most commonly through updates of the form</p> \[x_{k+1}=x_k+\alpha_k p_k\] <p>Where $p_k$ is the direction to step to and $\alpha_k$ controls the step size. This gives us a sequence ${x_k}$ and we terminate until a local minima is found. Broadly speaking, we choose $p_k$ to be a descent direction (i.e. moving in this direction reduces the function value).</p>]]></content><author><name></name></author><category term="blog"/><category term="optimization"/><summary type="html"><![CDATA[]]></summary></entry></feed>